{
 "cells": [
  {
   "cell_type": "raw",
   "id": "96a0250e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "author: Christof Claessens\n",
    "date: June 2025\n",
    "title: \"Attention mechanics\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06802ab4",
   "metadata": {},
   "source": [
    "In the previous notebook we prepared and massaged our text into input vectors that encode both tokens as well as their positions.  It's these input vectors that will be handled by the rest of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3708c9",
   "metadata": {},
   "source": [
    "# Self-Attention\n",
    "\n",
    "\n",
    "\n",
    "Self-Attention is a technique whereby each position in the input sequence can consider the relevancy of each other position in the same sequence when the representation for the sequence is being computed.  (Traditional \"attention\", as opposed to self-attention look at relations between two different sequences, input- and output, as opposed as using a single sequence.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1690776",
   "metadata": {},
   "source": [
    "## Simplified Self-Attention\n",
    "\n",
    "Let's take a simple sentence:\n",
    "\"I am learning this\"\n",
    "\n",
    "This is our input sequencen let's call it $x$ with 4 tokens: $x^{(1)}$, $x^{(2)}$, $x^{(3)}$ and $x^{(4)}$.\n",
    "\n",
    "In general if our context length is $T$ then we have $x^{(1)} \\ldots x^{(T)}$\n",
    "\n",
    "Each $x^{(i)}$ is a $d$-dimensional embedding vector representing a token.\n",
    "\n",
    "Now we will calculate a context vector $z^{i}$ for each $x^{i}$.  This vector will contain information from all vectors $x^{(1)} \\ldots x^{(T)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c0293",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
